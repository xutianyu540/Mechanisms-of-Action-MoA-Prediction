{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# Tabnet \n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCH = 200\n",
    "\n",
    "\n",
    "tabnet_params = dict(\n",
    "    n_d = 32,\n",
    "    n_a = 32,\n",
    "    n_steps = 1,\n",
    "    gamma = 1.3,\n",
    "    lambda_sparse = 0,\n",
    "    optimizer_fn = optim.Adam,\n",
    "    optimizer_params = dict(lr = 2e-2, weight_decay = 1e-5),\n",
    "    mask_type = \"entmax\",\n",
    "    scheduler_params = dict(\n",
    "        mode = \"min\", patience = 5, min_lr = 1e-5, factor = 0.9),\n",
    "    scheduler_fn = ReduceLROnPlateau,\n",
    "    seed = seed,\n",
    "    verbose = 10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogitsLogLoss(Metric):\n",
    "    \n",
    "    #比赛指定评价函数\n",
    "\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "    def __call__(self, y_true, y_pred):\n",
    "\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        aux = (1 - y_true) * np.log(1 - logits + 1e-15) + y_true * np.log(logits + 1e-15)\n",
    "        return np.mean(-aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_auc_all = []\n",
    "test_cv_preds = []\n",
    "\n",
    "NB_SPLITS = 7 # 7\n",
    "\n",
    "\n",
    "oof_preds = []\n",
    "oof_targets = []\n",
    "scores = []\n",
    "scores_auc = []\n",
    "SEED = [42,43,44]\n",
    "# SEED = (42,43,44)  \n",
    "for s in SEED:\n",
    "    tabnet_params['seed'] = s\n",
    "    mskf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, random_state = s, shuffle = True)\n",
    "    for fold_nb, (train_idx, val_idx) in enumerate(mskf.split(train, train[target_cols])):\n",
    "        print(b_,\"FOLDS: \", r_, fold_nb + 1, y_, 'seed:', tabnet_params['seed'])\n",
    "        print(g_, '*' * 60, c_)\n",
    "    \n",
    "        X_train, y_train = train[feature_cols].values[train_idx, :], train[target_cols].values[train_idx, :]\n",
    "        X_val, y_val = train[feature_cols].values[val_idx, :], train[target_cols].values[val_idx, :]\n",
    "    \n",
    "        model = TabNetRegressor(**tabnet_params)\n",
    "        \n",
    " \n",
    "        model.fit(\n",
    "            X_train = X_train,\n",
    "            y_train = y_train,\n",
    "            eval_set = [(X_val, y_val)],\n",
    "            eval_name = [\"val\"],\n",
    "            eval_metric = [\"logits_ll\"],\n",
    "            max_epochs = MAX_EPOCH,\n",
    "            patience = 20,\n",
    "            batch_size = 1024, \n",
    "            virtual_batch_size = 32,\n",
    "            num_workers = 1,\n",
    "            drop_last = False,\n",
    "     \n",
    "            loss_fn = F.binary_cross_entropy_with_logits\n",
    "        )\n",
    "        print(y_, '-' * 60)\n",
    "        \n",
    "\n",
    "        saving_path_name = 'TabNet_seed_'+str(tabnet_params['seed'])+'_fold_'+str(fold_nb+1)\n",
    "        saved_filepath = model.save_model(saving_path_name)\n",
    "\n",
    "        loaded_model =  TabNetRegressor()\n",
    "        loaded_model.load_model(saved_filepath)\n",
    "\n",
    "\n",
    "        preds_val = loaded_model.predict(X_val)\n",
    "        \n",
    "        #转换为二分类\n",
    "        preds = 1 / (1 + np.exp(-preds_val))\n",
    "        score = np.min(model.history[\"val_logits_ll\"])\n",
    "    \n",
    "        \n",
    "        oof_preds.append(preds_val)\n",
    "        oof_targets.append(y_val)\n",
    "        scores.append(score)\n",
    "    \n",
    " \n",
    "        preds_test = loaded_model.predict(x_test[feature_cols].values)\n",
    "        test_cv_preds.append(1 / (1 + np.exp(-preds_test)))\n",
    "\n",
    "oof_preds_all = np.concatenate(oof_preds)\n",
    "oof_targets_all = np.concatenate(oof_targets)\n",
    "test_preds_all = np.stack(test_cv_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
