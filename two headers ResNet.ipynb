{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.models as M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_min = 0.001\n",
    "p_max = 0.999\n",
    "\n",
    "def logloss(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred,p_min,p_max)\n",
    "    return -K.mean(y_true*K.log(y_pred) + (1-y_true)*K.log(1-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_res_model(n_features, n_features_2):\n",
    "    print(f'the input dim is {n_features}, {n_features_2}')\n",
    "\n",
    "    input_1 = L.Input(shape = (n_features,), name = 'Input1')\n",
    "    input_2 = L.Input(shape = (n_features_2,), name = 'Input2')\n",
    "\n",
    "    head_1 = M.Sequential([\n",
    "        L.BatchNormalization(),\n",
    "        L.Dropout(0.3),\n",
    "        L.Dense(512, activation='elu'), \n",
    "        L.BatchNormalization(),\n",
    "        L.Dropout(0.5),\n",
    "        L.Dense(256, activation='elu')\n",
    "        ],name='Head1') \n",
    "\n",
    "    input_3 = head_1(input_1)\n",
    "    input_3_concat = L.Concatenate()([input_2, input_3])\n",
    "\n",
    "    head_2 = M.Sequential([\n",
    "        L.BatchNormalization(),\n",
    "        L.Dropout(0.3),\n",
    "        L.Dense(n_features_2, activation='relu'),\n",
    "        L.BatchNormalization(),\n",
    "        L.Dropout(0.5),\n",
    "        L.Dense(n_features_2, activation='elu'),\n",
    "        L.BatchNormalization(),\n",
    "        L.Dropout(0.5),\n",
    "        L.Dense(256, activation='relu'),\n",
    "        L.BatchNormalization(),\n",
    "        L.Dropout(0.5),\n",
    "        L.Dense(256, activation='selu')\n",
    "        ],name='Head2')\n",
    "\n",
    "    input_4 = head_2(input_3_concat)\n",
    "    input_4_avg = L.Average()([input_3, input_4]) \n",
    "\n",
    "    head_3 = M.Sequential([\n",
    "        L.BatchNormalization(),\n",
    "        L.Dropout(0.3),\n",
    "        L.Dense(256, activation='swish'),\n",
    "        L.BatchNormalization(),\n",
    "        L.Dense(256, activation='selu'),\n",
    "        L.BatchNormalization(),\n",
    "        L.Dense(206, activation='sigmoid')\n",
    "        ],name='Head3')\n",
    "\n",
    "    output = head_3(input_4_avg)\n",
    "\n",
    "\n",
    "    model = M.Model(inputs = [input_1, input_2], outputs = output)\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.002),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.001), metrics=logloss)\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
