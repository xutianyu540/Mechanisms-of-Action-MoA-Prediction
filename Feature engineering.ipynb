{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "### Machine Learning ###\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../input/lish-moa/'\n",
    "train_features = pd.read_csv(data_dir + 'train_features.csv')\n",
    "train_targets_scored = pd.read_csv(data_dir + 'train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv(data_dir + 'train_targets_nonscored.csv')\n",
    "train_drug = pd.read_csv(data_dir + 'train_drug.csv')\n",
    "test_features = pd.read_csv(data_dir + 'test_features.csv')\n",
    "sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features2=train_features.copy()\n",
    "test_features2=test_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 变换为正态分布\n",
    "qt = QuantileTransformer(n_quantiles=100,random_state=42,output_distribution='normal')\n",
    "train_features[GENES+CELLS] = qt.fit_transform(train_features[GENES+CELLS])\n",
    "test_features[GENES+CELLS] = qt.transform(test_features[GENES+CELLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load,dump\n",
    "n_comp = 600  #<--Update\n",
    "pca_g = PCA(n_components=n_comp, random_state=42)\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "gpca= (pca_g.fit(data[GENES]))\n",
    "train2= (gpca.transform(train_features[GENES]))\n",
    "test2 = (gpca.transform(test_features[GENES]))\n",
    "#将pca转换的特征作为新的纬度扩展\n",
    "train_gpca = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test_gpca = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train_gpca), axis=1)\n",
    "test_features = pd.concat((test_features, test_gpca), axis=1)\n",
    "\n",
    "dump(gpca, open('gpca.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 50  #<--Update\n",
    "\n",
    "pca_c = PCA(n_components=n_comp, random_state=42)\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "cpca= (pca_c.fit(data[CELLS]))\n",
    "train2= (cpca.transform(train_features[CELLS]))\n",
    "test2 = (cpca.transform(test_features[CELLS]))\n",
    "\n",
    "train_cpca = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test_cpca = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train_cpca), axis=1)\n",
    "test_features = pd.concat((test_features, test_cpca), axis=1)\n",
    "\n",
    "dump(cpca, open('cpca.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "#去低方差特征\n",
    "c_n = [f for f in list(train_features.columns) if f not in ['sig_id', 'cp_type', 'cp_time', 'cp_dose']]\n",
    "mask = (train_features[c_n].var() >= 0.8).values\n",
    "tmp = train_features[c_n].loc[:, mask]\n",
    "train_features = pd.concat([train_features[['sig_id', 'cp_type', 'cp_time', 'cp_dose']], tmp], axis=1)\n",
    "tmp = test_features[c_n].loc[:, mask]\n",
    "test_features = pd.concat([test_features[['sig_id', 'cp_type', 'cp_time', 'cp_dose']], tmp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def fe_cluster_genes(train, test, n_clusters_g = 22, SEED = 42):\n",
    "    \n",
    "    features_g = GENES\n",
    "    #features_c = CELLS\n",
    "#使用kmeans生成聚类特征\n",
    "    def create_cluster(train, test, features, kind = 'g', n_clusters = n_clusters_g):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_genes = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_genes, open('kmeans_genes.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_genes.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_genes.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "    train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "   # train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features2 ,test_features2=fe_cluster_genes(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe_cluster_cells(train, test, n_clusters_c = 4, SEED = 42):\n",
    "    \n",
    "    #features_g = GENES\n",
    "    features_c = CELLS\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'c', n_clusters = n_clusters_c):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_cells = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_cells, open('kmeans_cells.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_cells.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_cells.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "   # train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "    train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features2 ,test_features2=fe_cluster_cells(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pca=pd.concat((train_gpca,train_cpca),axis=1)\n",
    "test_pca=pd.concat((test_gpca,test_cpca),axis=1)\n",
    "def fe_cluster_pca(train, test,n_clusters=5,SEED = 42):\n",
    "#pca应用于生成的kmeans特征\n",
    "        data=pd.concat([train,test],axis=0)\n",
    "        kmeans_pca = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_pca, open('kmeans_pca.pkl', 'wb'))\n",
    "        train[f'clusters_pca'] = kmeans_pca.predict(train.values)\n",
    "        test[f'clusters_pca'] = kmeans_pca.predict(test.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_pca'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_pca'])\n",
    "        return train, test\n",
    "train_cluster_pca ,test_cluster_pca = fe_cluster_pca(train_pca,test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cluster_pca = train_cluster_pca.iloc[:,650:]\n",
    "test_cluster_pca = test_cluster_pca.iloc[:,650:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_cluster=train_features2.iloc[:,876:]\n",
    "test_features_cluster=test_features2.iloc[:,876:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsquarecols=['g-574','g-211','g-216','g-0','g-255','g-577','g-153','g-389','g-60','g-370','g-248','g-167','g-203','g-177','g-301','g-332','g-517','g-6','g-744','g-224','g-162','g-3','g-736','g-486','g-283','g-22','g-359','g-361','g-440','g-335','g-106','g-307','g-745','g-146','g-416','g-298','g-666','g-91','g-17','g-549','g-145','g-157','g-768','g-568','g-396']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#选择特征重要性较高的特征生成统计特征\n",
    "def fe_stats(train, test):\n",
    "    \n",
    "    features_g = GENES\n",
    "    features_c = CELLS\n",
    "    \n",
    "    for df in train, test:\n",
    "        df['g_sum'] = df[features_g].sum(axis = 1)\n",
    "        df['g_mean'] = df[features_g].mean(axis = 1)\n",
    "        df['g_std'] = df[features_g].std(axis = 1)\n",
    "        df['g_kurt'] = df[features_g].kurtosis(axis = 1)\n",
    "        df['g_skew'] = df[features_g].skew(axis = 1)\n",
    "        df['c_sum'] = df[features_c].sum(axis = 1)\n",
    "        df['c_mean'] = df[features_c].mean(axis = 1)\n",
    "        df['c_std'] = df[features_c].std(axis = 1)\n",
    "        df['c_kurt'] = df[features_c].kurtosis(axis = 1)\n",
    "        df['c_skew'] = df[features_c].skew(axis = 1)\n",
    "        df['gc_sum'] = df[features_g + features_c].sum(axis = 1)\n",
    "        df['gc_mean'] = df[features_g + features_c].mean(axis = 1)\n",
    "        df['gc_std'] = df[features_g + features_c].std(axis = 1)\n",
    "        df['gc_kurt'] = df[features_g + features_c].kurtosis(axis = 1)\n",
    "        df['gc_skew'] = df[features_g + features_c].skew(axis = 1)\n",
    "        \n",
    "        df['c52_c42'] = df['c-52'] * df['c-42']\n",
    "        df['c13_c73'] = df['c-13'] * df['c-73']\n",
    "        df['c26_c13'] = df['c-23'] * df['c-13']\n",
    "        df['c33_c6'] = df['c-33'] * df['c-6']\n",
    "        df['c11_c55'] = df['c-11'] * df['c-55']\n",
    "        df['c38_c63'] = df['c-38'] * df['c-63']\n",
    "        df['c38_c94'] = df['c-38'] * df['c-94']\n",
    "        df['c13_c94'] = df['c-13'] * df['c-94']\n",
    "        df['c4_c52'] = df['c-4'] * df['c-52']\n",
    "        df['c4_c42'] = df['c-4'] * df['c-42']\n",
    "        df['c13_c38'] = df['c-13'] * df['c-38']\n",
    "        df['c55_c2'] = df['c-55'] * df['c-2']\n",
    "        df['c55_c4'] = df['c-55'] * df['c-4']\n",
    "        df['c4_c13'] = df['c-4'] * df['c-13']\n",
    "        df['c82_c42'] = df['c-82'] * df['c-42']\n",
    "        df['c66_c42'] = df['c-66'] * df['c-42']\n",
    "        df['c6_c38'] = df['c-6'] * df['c-38']\n",
    "        df['c2_c13'] = df['c-2'] * df['c-13']\n",
    "        df['c62_c42'] = df['c-62'] * df['c-42']\n",
    "        df['c90_c55'] = df['c-90'] * df['c-55']\n",
    "        \n",
    "        \n",
    "        for feature in features_c:\n",
    "             df[f'{feature}_squared'] = df[feature] ** 2     \n",
    "                \n",
    "        for feature in gsquarecols:\n",
    "            df[f'{feature}_squared'] = df[feature] ** 2        \n",
    "        \n",
    "    return train, test\n",
    "\n",
    "train_features2,test_features2=fe_stats(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_stats=train_features2.iloc[:,902:]\n",
    "test_features_stats=test_features2.iloc[:,902:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.concat((train_features, train_features_cluster,train_cluster_pca,train_features_stats), axis=1)\n",
    "test_features = pd.concat((test_features, test_features_cluster,test_cluster_pca,test_features_stats), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type'] != 'ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type'] != 'ctl_vehicle'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "test = test.get_dummies(data, columns=['cp_time','cp_dose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [x for x in train_targets_scored.columns if x != 'sig_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多标签分折\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "mskf = MultilabelStratifiedKFold(n_splits=7,random_state=7)\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "     train.loc[v_idx, 'kfold'] = int(f)\n",
    "train['kfold'] = train['kfold'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in train.columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold', 'sig_id']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
